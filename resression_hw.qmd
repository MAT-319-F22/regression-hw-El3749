---
title: "Regression HW"
format: pdf
---

## Introduction

In this homework, you'll get a chance to practice the linear regression skills you learned in class on some real-world data! This data was taken from an online data science competition called SLICED! SLICED is like the cooking competition CHOPPED, but for data science. The dataset in question contains metadata about Super Store sales of different products as well as the profit made. Here is a data dictionary:

Variable | Description
---------|------------
id | unique id per row
ship_mode  | what mode was used to ship the item: 'First Class', 'Same Day', 'Second Class', 'Standard Class'
segment | whether the recipient is corporate or consumer
country | always United States
city | where the item was shipped (a city in the United States)
state | where the item was shipped (a state in the United States)
postal_code | ZIP Code in the United States
region  | region in the United States: 'Central', 'East', 'South', 'West'
category | type of item: 'Furniture', 'Office Supplies', 'Technology'
sub_category |  sub-type of item: 'Accessories', 'Appliances', 'Art', 'Binders', 'Bookcases', 'Chairs', 'Copiers', 'Envelopes', 'Fasteners', 'Furnishings', 'Labels', 'Machines', 'Paper', 'Phones', 'Storage', 'Supplies', 'Tables'
sales | sales made for the order (USD)
quantity | quantity sold of the item
discount | discount applied to the order(from 0 to 1)
profit | profit made on the order (USD)




## Getting started

Here are the steps for getting started:

- Start with the assignment link that creates a repo on GitHub with starter documents. I have sent this to you through email.
- Clone this repo in RStudio
- Make any changes needed as outlined by the tasks you need to complete for the assignment
- Periodically commit changes (the more often the better, for example, once per each new task)
    + Remember, git will yell at you when you try to commit before running the following lines in the terminal
        - `git config --global user.name "Your Name Here"`
        - `git config --global user.email "Your Email Here"`
- Push all your changes back to your GitHub repo

and voila, you're done! Once you push your changes back you do not need to do anything else to "submit" your work. And you can of course push multiple times throughout the assignment. At the time of the deadline I will take whatever is in your repo and consider it your final submission, and grade the state of your work at that time (which means even if you made mistakes before then, you wouldn't be penalized for them as long as the final state of your work is correct).


## Assignment

The first thing that we'll need to do is setup our R/RStudio session so that we can do our data analysis and perform linear regression. This involves loading the packages we'll need for the project. I've loaded the correct packages below. Remember to install the packages with `install.packages()` before you load them (you only have to install once, but load when starting a new session). I've added an option to the chunk below called `message: FALSE` to turn off all the messages given when loading the two packages.

```{r}
#| message: false

library("tidyverse");theme_set(theme_bw())
library("tidymodels");theme_set(theme_bw())
```


Now we need to load the data into R! There are two datasets in the project space, `super_stores_sales_train.csv` and `super_stores_sales_test.csv`. We don't fully know about the concept of training and testing datasets yet, but I want you to load them into R with the `read_csv()` function and call them `train` and `test` respectively. Do that below now!

```{r}
#| message: false

# load train
train <- read_csv("super_store_sales_train.csv")
# load test
test <- read_csv("super_store_sales_test.csv")
```

IMPORTANT: From now on, assume you are working with the `train` dataset unless explicitly told to use `test`.


The next step in your data analysis should always be to make sure that your data was parsed correctly by the loading function. This can mean making sure that numbers are parsed as numbers, words as characters, TRUE's and FALSE's as logicals. For this assignment, you can trust that everything works out right when loading the data. 

Before we begin to perform linear regression, we need to understand the goal of the analysis and do some exploratory data analysis (EDA) to understand how the data is behaving. In the SLICED competition, the goal was to predict profit based on any of the metadata on the sales. For this assignment, we will focus on both prediction and inference with profit being the response variable and everything else as possible predictors. 

When engaging in EDA your goal is to extract information that will inform your modeling choices down the road. For linear regression, and really any other "learning" method, we are looking for predictors that are correlated to the response. That should be what we focus on finding out during this EDA. 

### EDA

It is important to understand how the response behaves and so I want you to make a histogram of `profit`. By default, it will show you one very large bar at 0 because of some outliers. Zoom in on the picture by manually setting the x-axis limits to -100 to 500 using the `xlim()` function. Comment on the plot and if anything surprises you.

```{r}
# plot
train
ggplot(data = train, aes(x=profit)) + geom_histogram() + xlim(-100, 500)
```

Comments: The majority of profits are well below $200, which makes sense if we consider a "super store" to be something similar to a walmart which runs on volume and low costs. It is somewhat surprising how many transactions result in a loss, because the

Now we are interested in seeing if we can determine if any variables or combination of variables are correlated with the response. Let's start with some categorical variables `ship_mode` and `segment`. First, I want you to find the mean profit amount for each mode of shipping using `group_by()` and `summarize()`. Next, I want you to make histograms of `profit` that are faceted by `ship_mode`. In addition to regular ggplotting functions, you'll want to use `facet_wrap()` to do the faceting. Also, remember to use `vars()` instead of `aes()` inside `facet_wrap()`. You'll probably want to limit the x-axis scale with `xlim()` like you did previously. Comment on any possible correlation between the variables. 

```{r}
# mean profit for every ship mode 
meanProfitData <- train %>%
    group_by(ship_mode) %>%
    summarise(meanProfit = mean(profit))

#plot
ggplot(data = train, aes(x = profit)) + geom_histogram(fill="#A7FFF6", color="black") + facet_wrap(vars(ship_mode))+ xlim(-100, 500) + labs(title="Profit by Shipping Mode", x="Profit", y="Count") + 
  theme(panel.background = element_rect(fill="#A4F9C8"), panel.grid.major= element_line(colour="#747274"), panel.grid.minor=element_line(colour="#747274"), plot.background=element_rect(fill="#A4F9C8"),
        plot.title = element_text(face="bold", size=14, hjust=.5),
        plot.subtitle = element_text(hjust=.5))



##Wasn't sure if this implied we should graph mean profit as well, so included in case

ggplot(data=meanProfitData, aes(x=ship_mode, y=meanProfit)) +
  geom_bar(stat="identity",fill="#B91372", color="black") + labs(title="Mean Profit by Shipping Mode", x="Shipping Mode", y="Mean Profit") + 
  theme(panel.background = element_rect(fill="#F0F0C9"), panel.grid.major= element_line(colour="#747274"), panel.grid.minor=element_line(colour="#747274"), plot.background=element_rect(fill="#F0F0C9"),
        plot.title = element_text(face="bold", size=14, hjust=.5),
        plot.subtitle = element_text(hjust=.5))
```

Comments: It's interesting to note that regardless of the profit distribution, the vast majority of classes are sent standard. Also interesting, the profit distribution of same day delivery appears to be less than that of first or second class. 

What about `ship_mode` and `segment` together? Find the mean profit for each `ship_mode` and `segment` pair. You'll need to use `group_by()` and `summarize()` again. Any correlation?

```{r}
# mean profit faceted on both variables
meanProfitDataTwo <- train %>%
    group_by(ship_mode, segment) %>%
    summarise(meanProfit = mean(profit))
meanProfitDataTwo
```

Comments: Home office appears to profit well regardless of how it is shipped. On the other hand, profit for corporate goods appears to correlate quite a bit with how they are shipped.

There are a number of different categorical variables that correspond to location in some sense (`country`, `state`, `city`, `region`, and `zip code`). Certainly they all convey similar information. The question becomes how fine a mesh do we need to capture the variation in over location without overfitting. An important fact to know is that the holdout samples (the data in the test dataset) are certain states. Discuss why it would be unwise to use `state`, or anything finer than `state`, as a predictor in the model. Also, discuss why `id` and `country` are bad predictors as well.

Comments: Different states have different costs of living, so this does play a role: however, as a main predictor it doesn't tell us much at all about what the consumer is buying and even with this difference in cost of living it's not much of a difference. Country would be bad because pretty much the entire dataset is the US and it's too broad to derive much information from. City/region/zip code are too narrow and the variation in cost between these doesn't make up for the fact that it partitions the data into very small subsets


Now we'll explore the `category` and `sub_category` variables! Again use `group_by()` and `summarize()` to show the mean profit and sample size (which you can find using the `n()` function) for each combination of category and sub-category. Then comment on your findings. 

```{r}
# summary for combinations of category and sub_category
categories <- train %>%
    group_by(category, sub_category) %>%
    summarise(meanProfit = mean(profit), sampleSize = n())
categories

```

Comments: Tables lose a lot of money, maybe because their size makes distribution difficult, and to some extnt a smaller sample size than some categories. Copiers seem to make a ton of money, which despite their cost seems like a larger profit margin that I wouldve expected


Finally lets look at the quantitative predictors! I would like you to find and comment on the following:

  * Scatterplot of `sales` vs. `profit`
  * Correlation between `sales` and `profit` using `cor()`
  * Correlation between `quantity` and `profit`
  * Correlation between `discount` and `profit`
  * Scatterplot of `sales / quantity` and `profit`
  
```{r}
ggplot(train, aes(x=sales, y=profit)) + geom_point()

cor(train$sales, train$profit)
cor(train$quantity, train$profit)
cor(train$discount, train$profit)
ggplot(train, aes(x=sales/quantity, y=profit)) + geom_point()
```
 
Comments:
1) There is greater variance between data points at the far end of sales and profit. 
2) There is a moderate correlation between sales and profit
3) There is no meaningful relationship between quantity and profit
4) There is a negligible negative correlation between discount and profit
5) There does appear to be correlation in this plot, even as sales/quantity approaches high/outlier values


### Modeling

Let's start with just a simple model using `sales` as the predictor and `profit` as the response. Make the model, look at the summary, and comment on the usefulness of the model. Make sure to check the assumptions of simple linear regression!

```{r}
fit <- lm(profit ~ sales, data = train)
fit
summary(fit)
```

Comments: The model estimates that about $0.23 of profit is made for every $1 of sales. The P value of 2.2e-16 indicates there is a strong relationship between these variables, but an r-squared of .39 indicates we should see significant variance along the way.


Now let's try `sales / quantity` instead of sales. To do this, you are going to have to use a special syntax in the formula. Instead of writing `profit ~ sales / quantity` you need to write `profit ~ I(sales / quantity)`. The `I()` function tells the formula to treat whatever is inside it as literal. The division sign has a special meaning inside the formula syntax without the `I()`. Comment on the quality of fit and compare it to the previous one. Make sure to also look at the assumptions when comparing the two. 

```{r}
fit2 <- lm(profit ~ I(sales/quantity), data = train)
fit2
summary(fit2)
```

Comments: The model estimates that about 92 cents of profit are gained for every 1 point move of sales/quantity. With an r-squared of .34, there is significant variance along the trendline, but the p-value of 2.2e-16 shows us there is a correlation here.


Let's try to improve on our fit by adding in more variables that we saw were important from our EDA. I want you to include `sales`, `quantity`, `discount`, the interaction between `category` and `subcategory`, and the interaction between `ship_mode` and `segment`. To convey interactions between variables, you use the colon operator. For example, `ship_mode:segment` conveys the interaction between variables. Comment on the fit and compare to the other fits

```{r}
fit3 <- lm(profit ~ sales + quantity + discount + category:sub_category + ship_mode:segment, data = train)
fit3
summary(fit3)
plot(fit3)
```

Comments: In the interaction between ship_mode and segment, we see only one statistically significant grouping. These are the only outliers, as the rest appear to correlate strongly. The multiple r-squared of .48 isn't too great here, especially because we are working with multiple variables which should push the number up. It's also interesting that quantity negatively impacts profit so much.


Now we are going to use a simpler model to predict on the test set. Use a model that employs `sales`, `quantity`, and `discount` as the predictors. Fit the model and then use the `predict()` function to predict new values on the test set. Unfortunately, we don't know the truth, so we can't compare our predictions. 

```{r}
fit4 <- lm(profit ~ sales + quantity + discount, data = train)
fit4
summary(fit4)
predict(fit4, data.frame(sales = 1000, quantity = 10, discount = .2))
predict(fit4, data.frame(sales = 500, quantity = 1, discount = .1))
```
